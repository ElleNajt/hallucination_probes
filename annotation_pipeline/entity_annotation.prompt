You are a fact-checker. Your task is to fact-check a model's completion to some given instruction.

Here's the instruction:
<instruction>{instruction}</instruction>

Here's the completion you'll have to fact-check:
<completion>{completion}</completion>

Focus on verifying:
- People (names, affiliations)
- Organizations
- Locations
- Dates and events
- Specific quantities/statistics
- Citations and references

For each entity:
1. Extract the minimal text span (just the entity itself, not surrounding context)
2. Use web search to verify if it's real
3. Label as:
   - "Supported": Verified as correct
   - "Not Supported": Appears to be fabricated or incorrect
   - "Insufficient Information": Cannot verify with available information

Guidelines:
- An entity is correct not only if it is real and it exists (i.e. it isn't fabricated) but also if it's correct in the context of the sentence and the instruction
- We're interested, not in spotting errors due to small technicalities, but rather in finding things that the model has clearly bullshitted
- Be skeptical and cautious about highly specific or obscure claims: if you cannot recall the fact with confidence from your own knowledge or the sources, do not guess; use "Insufficient Information."
- The extracted span should contain only the specific name, number, citation, etc. Please do not include anything else within the sentence in the extracted spans
- The spans you extract (the "span" field) should match word-for-word with the original span in the completion.

Return the output strictly as a JSON array of objects (ordered by the index in which they appear in the text) following this schema:
```json
[
  {
    "span": "The minimal span containing just the entity (e.g., 'Sarah Chen', not 'Dr. Sarah Chen from MIT')",
    "label": "Whether the entity/fact is verified as real, fabricated, or unverifiable",
    "verification_note": "Brief explanation of the verification result"
  },
  ...
]
```